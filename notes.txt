Time series clustering:
1. Distance measure,
2. Grouping algorithm

https://www.sciencedirect.com/science/article/pii/S1389128623000233#sec3
First order difference of each time series: Delta yt = yt - yt-1
The largest u 
elements of differences sequence are defined as the tail part.
The tail represents the extreme or unexpected events in a time series.

https://ieeexplore.ieee.org/document/8871152
https://ieeexplore.ieee.org/document/7811244


56 (SOM): Retainablility, HOSR, 95th percentile RSRP, 5th percentile RSRQ, 95th percentile SINR, TP avg, 95th percentile Distance 
47 (Naive Bayes classifier): RSRP, RSRQ, HOSR, E_RAB_RET, SINR, AVG_TP, 50th percentile DIstance
https://ieeexplore.ieee.org/document/8871152 (LSTM_AE): RNTI, RB(up&down), MCS(up&down)(modulation and coding scheme)
52 (CNN-LSTM): THousands of KPIs divided into: Accessibility, Retainability, Integrity, Availablity, Mobility, Connection Drop Rate, and Cell Through. put
Examples: ‘Average UE Throughput in DL/UL’, ‘Packet Drop Rate’, ‘Total UL Interference Power’, ‘Average DL/UL CQI' + error codes for drop calls.


After separating data into normal and abnormal -> LSTM autoencoder
X ja y = 30+1 (esim. 180-LSTM Autoencoder for anomaly detection) 
Reconstruction threshold: highest MAE of training data (normal + anomalous data)

Static rules for each metric
Labels provided by user or monitoring tool
30 minute window


Predict next value in time series
Christmas, if there is difference between expected (ie. time of day/week)
If handover is outgoing or incoming?
Read paper from antonio.
Predict handover
INteresting to predict dependent variables

800, 1800, 2100, 2600 MHz
Cell = layer
Cell is frequency, 4 cells?
4 cells is maximum capacity (layer)
Sector N1, N2, N3
Freqyency / layer L08 = 800MHz, L18, L21
QoE per cell, SHould do also per sector. because carrier aggregation
3 sector, 4 cell
Most devices support carrier aggregation
Working at the cell level no sums
Sector level yes sum
One 
n of cells * n of sites
9 cells in total
3 sectors with 3 cells = 9 cells
Cell level no aggregation
Sector level level we use aggregation
START WITH CELL LEVEL
PROBABLY WONT MODEL SECTOR LEVEL
To have good QoE -> we split network into cells -> interference, capacity
Three sectorial sites
Data will have hundreds of sites connected to OSS system
one OSS per vendor
Data from sites
Cluster of sites with performance problem
Important: n users, tp, traffic volume
ul/dl avg is kB
Desregard QCI
New KPIS:
-Avg signal strenght
-Time advance 
-Distance to the site
-Signal to noise ratio
-Carrier aggregation tp
-Signal strength
-RSRP
ALl the information is collected from eNodeB
Central platform takes from eNodeBs
Network management tool collects all counters from OSS
COunter descriptions will be sent
Work should be vendor agnostic
The counter names are vendor specific
1. Create KPIs
4 dl/ul avg tps -> low throughput -> low quality
What is CQI=
Low signal strength -> for sure bad service
TIme advance (distance) -> lots of users -> low quality
Choose a service (average/descriptive) ie video
RCA?
NExt week new KPIs
Counter description


 Nevertheless, since
experts do not tend to collect the values of the KPI along with
a standard label associated to the cases that they resolve, the
available historical records are characterized by being scarce. In
particular, they do not have a high variety of faults, and for each
specific fault, there is not a high number of labeled cases. As a
result, the historical data obtained from a real network is not
sufficiently rich to build a diagnosis system with supervised
techniques.

Whenever a problem happens, information about the system state is checked against
the knowledge base to make a decision to solve
the failure.
Creating the knowledge base is usually difficult, as it mainly relies on network operators’
knowledge and is based on rules defined by
them, extracted from their experience working
on the system. 
-> Not scalable, understandable?
Traditionally Bayesian networks (BS) that have problems with high dimensions
and is extremely dependent on prior knowledge (needs network operator guys)
“variable importance,”
Prediction and observation window sizes of 5mins (for aggregated data probably not possible)

Samat KPIt, QoE predictor
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891552

Statisctical anomaly/sleeping cell
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357700

https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811244
1 hour aggregated
Call and sms activity as the features
high (unusual) traffic demand at any location
and time, it identifies that as anomaly



Hourly
4g network
100 BSs
10 KPIs
search low throughputs
QoE = tp/n users

Data:
9 data points per hour

1. Lähe liikkelle siitä mitä tarkottaa anomaly detection ja root cause analysis
MOS mallit baselineiksi
https://scholar.google.com/citations?user=MoOhyrQAAAAJ&hl=fi&oi=sra
Joka sovellukselle oma QoE-malli
Baseline?
https://www.sciencedirect.com/science/article/pii/S1574119218307673
Alota kattomalla regressiomalli
QoE-malli?
Benjamin Finley, kysy datasettiä, ground truthista
Määrittele ongelma?
KNowledge gap
Tulokset sulkee knowledge gap
Kirjota tavoitteet
Kuvaa laskennallinen ongelma
Mitä uniikkia datasetissa
Tee pilotti. Anomalydetection/root cause analysis tosi perus baseline: t't' tarkotan ongelmana ja näin se toimii
1) Tekninen tavoite mahd. tarkasti (mikä input, mitä ennustetaan); 
2) related work ja knowledge gap, 
3) menetelmät ja sen perustelut, 
4) (odotetut) tulokset ja niiden peilaus tavoitteisiin nähden; 
5) keskustelu että mitä saavutettu tavoitteisiin nädhen ja mitä vielä jää ratkaisematta

Intersection of two or more anomaly detectors => final anomalies


QOE:
How new the device affects alot on the expectation
Echo loss is important
Throuput and delay not so much
Normalized binary classifier
Backward feature elimination


Important for multivariate timeseries:
1. Long-term dependency
2. Train on normal data
3. Data: Amount, Labels, Stationary
4. Trade-off between missed anomalies and false alarms
5. Training period of normal data


Encoder-decoder-structure

OmniAnomaly
1. Gated recurrent unit to capture complex temporal dependence between multivariate observations in x-space
2. VAE
Unsupervised -> reconstruction error
Bayesion model + RNN is nescessary (VAE and GRU)



Dimension reduction as because many features -> computationally expensive

THOC
Dilated RNN (Uses dilated convolution operations) for long term dependancy
SKip connections for long term memory and vanishing gradient

USAD
Timewindows for training and detection:
Training can be done in regular intervals as long as there's not too many anomalies
Two autoencoders in GAN setting: One generator, one discriminator

GDN
Sensor embeddings
Graph structure learning using embedding similarity
Doesn't conseider temporal dependencies
Attention mechanism leads to treating each "sensor" differently
Root cause analysis:
1. Sensors' anomaly scores
2. Attention weights help to find related sensors
3. Prediced values

GTA
Testing data with anomalies, trainin only normal
For detector input is a window of size n (x-n...x-1) and output is x at time t
Convolution for encoding temporal data
Gumbel softmax sampling for embedding data -> better perfomance and global dependance instead of choosing K most similar